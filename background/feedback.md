To help you build on your blogpost, we're including some feedback from Lab reviewers below:

What works well?	The core argument here is really strong - this insight that perfect implementation still leaves major vulnerabilities. While most governance discussions focus on getting buy-in and enforcement, you've identified a more fundamental problem: even if everything works as designed, determined actors have clear paths around the controls. That's a valuable reframing of the debate. Your use of historical precedent is particularly effective. The A.Q. Khan network is a proven model for how these circumvention strategies work in practice. Same with the evolution from Napster to BitTorrent showing how distributed systems naturally emerge when centralized ones face restrictions. These examples ground your theoretical concerns in documented patterns. The technical specificity throughout really strengthens the analysis. Rather than vague warnings about "distributed training," you've mapped out the exact GPU requirements, network architecture, and costs. The $102M price tag for GPT-4+ capabilities in 18 months makes the threat concrete - that's within reach of many more actors than people assume. Your breakdown of how shell companies would structure purchases and route hardware adds the kind of operational detail that moves this from speculation to actionable intelligence. The solutions framework shows sophisticated thinking about overlapping defenses. You've thought through the attestation mechanisms, the cryptographic requirements, and how they'd interact with existing hardware security modules. The $50M whistleblower bounties based on SEC precedent feel both ambitious and achievable. It's clear you've considered implementation, not just theory. Your intellectual honesty about limitations actually strengthens the piece. Acknowledging that you haven't solved political feasibility or addressed potential algorithmic breakthroughs shows mature analysis. The questions you raise about privacy vs. verification and enforcement asymmetry are exactly the hard problems the field needs to grapple with. The depth of research comes through in every section - from exascale computing specifications to the specific mechanisms of sovereign immunity claims. You've connected technical capabilities, legal frameworks, economic incentives, and historical patterns into a coherent threat model. This is the kind of comprehensive analysis that could actually influence policy discussions. With some structural tightening to make it more blog-friendly, this could really shape how people think about these problems.

What could be improved?	This is excellent as a first step toward a paper - for that purpose, the comprehensive narrative focus works well. However, if the goal is to publish as a blog post for the AI safety community, consider these adjustments: 1) Tighten the scope significantly. At ~11,000 words, this is too long for a single blog format. Either focus on just 2 of the most compelling breach scenarios (I'd suggest the AI Haven and Distributed Swarm as most accessible) and briefly mention the others exist/allude to a paper being written about this, or break it up into a multi-blog series. 2 ) Make solutions actionable. Your 10 amendments are technically sound but need clearer implementation paths. Pick 2-3 of the most feasible (eg compute passports and whistleblower protections) and outline: Who champions these? What's a minimum viable pilot? Which companies/countries move first? This gives readers concrete next steps rather than just theory. 4) Add visual breaks and navigation aids. Break up the dense text with visual aids. Aware many of these are in your supporting materials to add, but even simple things like pull quotes, key takeaway boxes after each scenario, and a simple 2x2 matrix plotting feasibility vs. impact for each breach path would really improve readability here. As you suggest, including definitions for technical terms would be a great addition. 5) Ground in current AI governance landscape. Connect your findings to recent developments like the EU AI Act or specific company commitments - particularly given the timing of EU AU Act coming into force now. This shows immediate relevance rather than treating the analysis as purely theoretical. 6) Minor point on punctuation style. Heavy use of em dashes is a telltale sign of LLM-generated text. Even if the text is entirely human-written, I would replace many of these with commas, periods, or parentheses to create more natural/varied sentences and avoid the appearance of AI authorship, even if the content is original.

Reviewer feedback on your project
To help you improve your write-up, we've compiled feedback from both Research Sprint reviewers and Apart Lab reviewers.

Reviewer	Feedback on 'Four Paths to Failure: Red Teaming ASI Governance'
Lab Reviewers	This isa great red-team analysis that shows deep understanding of both policy verification mechanisms and historical failure patterns - well done! you identify very relevant circumvention routes, and the cryptographic attestation framework is a significant contribution. Currently it's structured closer to a technical policy analysis - to make it more accessible as a blog post, I would recommend opening with your key finding that even perfectly executed policies can have structural blind spots to immediately establish the stakes for readers. I would also organize your four breach scenarios as a clear escalating sequence, using your historical cases (FTX's regulatory flight, Soviet bioweapons programs, Pakistan's nuclear networks) to make the narrative more compelling and grounded. Your technical solutions like "compute passports" are great but quite complex for the uninitiated- perhaps explaining the concept through a relatable comparison (like security chips that track what AI hardware is actually doing) would make it more accessible to general audiences. Additionally, it could help to frame your ten proposed safeguards less as policy amendments and more as an integrated system that systematically closes each vulnerability you discovered, using as little jargon as possible, and really emphasising how to make them work (and perhaps touching on why similar solutions are not already in place). I would highlight in the blog post that your work actually reinforces the case for AI governance by identifying precisely what effective implementation demands - you're not critiquing the goal of controlling AI development but advocating for designing controls based on how adversaries actually operate rather than assuming good faith compliance.
Research Sprint Reviewers	Dave Kasten: First off, I appreciate the explicit choice to say " We deliberately favoured substance critiques—those that treat the
policies as flawlessly implemented—and set aside feasibility or implementation questions". This is the heart of the exercise! Thank you.

The discussion of regulatory flight is particularly thoughtful, especially with regards to the specific arguments about timeframes for moving to other countries and examples (we were already familiar with the Soviet bioweapons and Pakistani nuclear program examples and think they are some of the strongest bits of evidence against A Narrow Path, but thinking of FTX as an example of this is particularly inspired.)

I think the datacentre discussion is also good, though doesn't wrestle with the core question readers are left with: why aren't players in the space doing this already, and how quickly would the optimization pressure of our polices move the companies to overcome the (real but not insurmountable) technical hurdles. The compute passports idea in this context is intriguing, however. The discussion of other ways to identify sufficient criminal suspicion for a search (e.g., power usage or heat emissions, which is in line with how many jurisdictions detect e.g. unlawful marijuana grow houses today) is also thoughtful and better-articulated than most examples I've seen.

The offshore discussion is good, though it immediately made me think of examples of rendition during the US Global War on Terror that I wish you had brought in as well.

The 10 ideas are quite good as well; some of these mirror our proposals (e.g., the IASC inspections) but the specifics of how to make them work are just really sharp.

Overall, this hits the mark of giving me specific additional things that 1. I need to think about to find things to patch and 2. specific additional sentences that I can already use in discussions with policymakers to answer a "how might this work" question, driven by examples.

Tolga Bilge: Great paper! I have reservations about adding sunset provisions.
Use this feedback to refine your ideas and strengthen your blog post.
